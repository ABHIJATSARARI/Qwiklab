{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPl/ADtWiAQT64MD+vONWn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ABHIJATSARARI/Qwiklab/blob/main/OpenVINO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> you will need to have the OpenVINO toolkit installed and configured on your system. Additionally, you will need to have access to the pre-trained roBERTa-base model.\n",
        "\n"
      ],
      "metadata": {
        "id": "mF_4nEZnek-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h55V63TleaO3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import RobertaTokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will load the pre-trained model and tokenizer."
      ],
      "metadata": {
        "id": "FwCGSyFAesbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.RobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n"
      ],
      "metadata": {
        "id": "byEN3iOjepnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will then define a function that takes a sentence as input, tokenizes it using the tokenizer, and feeds it to the model for prediction."
      ],
      "metadata": {
        "id": "oonK7yFXexby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_sentiment(sentence):\n",
        "    input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)\n",
        "    outputs = model(input_ids)\n",
        "    logits = outputs[0]\n",
        "    probabilities = torch.softmax(logits, dim=1).detach().tolist()[0]\n",
        "    return {'negative': probabilities[0], 'positive': probabilities[2], 'neutral': probabilities[1]}\n"
      ],
      "metadata": {
        "id": "0RmBQeDae67G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use this function to classify the sentiment of a given sentence.\n",
        "\n"
      ],
      "metadata": {
        "id": "wuU_RPrYe9h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I love this movie!\"\n",
        "result = classify_sentiment(sentence)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "WNdQDIw9e_N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This should output something like the following:\n",
        "\n",
        "{'negative': 0.004142254695385456, 'positive': 0.9862336511611938, 'neutral': 0.009624091044902325}\n"
      ],
      "metadata": {
        "id": "IwiCRN9pfBP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To optimize the model using OpenVINO, we will first convert the PyTorch model to an Intermediate Representation (IR) format that can be used with the OpenVINO toolkit. We will do this using the following command:"
      ],
      "metadata": {
        "id": "Ctu7Akn4fHjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "!python -m torch.utils.bottleneck \\\n",
        "--model_name roberta-base \\\n",
        "--output_dir /path/to/output/directory \\\n",
        "--model_file /path/to/pytorch/model/file \\\n",
        "--reverse_input_channels\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "p2f1M-W0fLAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the IR model has been generated, we can load it into OpenVINO and use it for inference."
      ],
      "metadata": {
        "id": "bdapWhVTfRk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openvino.inference_engine as ie\n",
        "\n",
        "# Load the IR model\n",
        "model_xml = \"/path/to/ir/model/file.xml\"\n",
        "model_bin = \"/path/to/ir/model/file.bin\"\n",
        "net = ie.IENetwork(model=model_xml, weights=model_bin)\n",
        "\n",
        "# Load the inference engine\n",
        "ie_core = ie.IECore()\n",
        "\n",
        "# Set up the input and output blobs\n",
        "input_blob = next(iter(net.input_info))\n",
        "output_blob = next(iter(net.outputs))\n",
        "\n",
        "# Create an inference request object\n",
        "exec_net = ie_core.load_network(network=net, device_name=\"CPU\", num_requests=1)\n",
        "\n",
        "# Run inference on a given sentence\n",
        "input_data = {input_blob: input_ids.detach().numpy()}\n",
        "result = exec_net.infer(inputs=input_data)[output_blob]\n",
        "\n",
        "probabilities = torch.softmax(torch.tensor(result), dim=1).detach().tolist()[0]\n",
        "print({'negative': probabilities[0], 'positive': probabilities[2], 'neutral': probabilities[1]})\n"
      ],
      "metadata": {
        "id": "9w_ZLpIPfEp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This should give you the same result as the original PyTorch implementation, but with the added benefit of being optimized for use with OpenVINO."
      ],
      "metadata": {
        "id": "O6_EjThAfWQA"
      }
    }
  ]
}